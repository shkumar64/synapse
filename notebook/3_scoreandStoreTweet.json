{
	"name": "3_scoreandStoreTweet",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "fsi",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2
		},
		"metadata": {
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/4f560746-383b-468f-bdfa-bc5acc08a8f1/resourceGroups/DDiB-FSI-Lab/providers/Microsoft.Synapse/workspaces/synapsefsibnkhackbrku4oli5l4c2/bigDataPools/fsi",
				"name": "fsi",
				"type": "Spark",
				"endpoint": "https://synapsefsibnkhackbrku4oli5l4c2.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/fsi",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "2.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28
			}
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"## *****For Demonstration purpose only, Please customize as per your enterprise security needs and compliances***** \n",
					"Disclaimer: By accessing this code, you acknowledge the code is made available for presentation and demonstration purposes only and that the code: (1) is not subject to SOC 1 and SOC 2 compliance audits; (2) is not designed or intended to be a substitute for the professional advice, diagnosis, treatment, or judgment of a certified financial services professional; (3) is not designed, intended or made available as a medical device; and (4) is not designed or intended to be a substitute for professional medical advice, diagnosis, treatment or judgement. Do not use this code to replace, substitute, or provide professional financial advice or judgment, or to replace, substitute or provide medical advice, diagnosis, treatment or judgement. You are solely responsible for ensuring the regulatory, legal, and/or contractual compliance of any use of the code, including obtaining any authorizations or consents, and any solution you choose to build that incorporates this code in whole or in part. \n"
				],
				"attachments": null
			},
			{
				"cell_type": "code",
				"source": [
					"import pip #needed to use the pip functions\n",
					"for i in pip.get_installed_distributions(local_only=True):print(i)"
				],
				"attachments": null,
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"import urllib.parse, base64\n",
					"import json\n",
					"import requests\n",
					"import pandas as pd\n",
					"import datetime\n",
					"import pytz\n",
					"from azure.core.credentials import AzureKeyCredential\n",
					"from azure.ai.textanalytics import TextAnalyticsClient\n",
					"\n",
					"#sentiment_url = 'https://cog-all-brku4oli5l4c2-bnkhack.api.cognitive.microsoft.com/text/analytics/v3.0/sentiment' # service address \n",
					"sentiment_url = 'https://cog-all-brku4oli5l4c2-bnkhack.cognitiveservices.azure.com/'\n",
					"api_key = '3e9db80bed824b278b0eeb4b0e728f48'          # Azure Cognitive API Key, replace with your own key\n",
					"\n",
					"\n",
					"credential = AzureKeyCredential(api_key)\n",
					"text_analytics_client = TextAnalyticsClient(endpoint=sentiment_url, credential=credential)"
				],
				"attachments": null,
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"from azure.storage.blob import (\n",
					"    BlockBlobService\n",
					")\n",
					"\n",
					"accountName = \"stfsibnkhackbrku4oli5l4c\"\n",
					"accountKey = \"SgNgr55lJr1ow65alp/+5tOh/VhkqoWkXV6t1U9/0mx+A5+jPq9ovyNrMHD+liY4+482tvUUbWP63Oj1Jla8kg==\"\n",
					"containerName = \"risk\"\n",
					"\n",
					"blobService = BlockBlobService(account_name=accountName, account_key=accountKey)"
				],
				"attachments": null,
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"import datetime\n",
					"import pytz\n",
					"\n",
					"currDate = datetime.datetime.now(pytz.timezone('US/Central'))\n",
					"blobName = \"TwitterData/\" + str(currDate.year) + \"/\" + str(currDate.month) + \"/\" + str(currDate.day - 1)\n",
					"print(blobName)\n",
					"\n",
					"   "
				],
				"attachments": null,
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Read out CSV file with list of all tickers\r\n",
					"nqSdf = spark.read.load('abfss://risk@stfsibnkhackbrku4oli5l4c.dfs.core.windows.net/Portfolio/PortfolioCik.csv', \r\n",
					"    format='csv', \r\n",
					"    sep=\",\",\r\n",
					"    header=True)\r\n",
					"\r\n",
					"portfolioData = nqSdf.toPandas()\r\n",
					"display(portfolioData)"
				],
				"attachments": null,
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"import glob\n",
					"import re \n",
					"\n",
					"filename_prefix = \"/\" + blobName \n",
					"filename_objects = blobService.list_blobs('risk', prefix = filename_prefix)\n",
					"#print(filename_objects)\n",
					"\n",
					"for index, portfolio in portfolioData.iterrows():\n",
					"   print(portfolio.Ticker)\n",
					"   if portfolio.Ticker :\n",
					"      filtered = [fileinfo.name for fileinfo in filename_objects if portfolio.Ticker in fileinfo.name]\n",
					"      print(filtered)\n",
					"      consolidatedtweets = pd.DataFrame()\n",
					"\n",
					"      for tickerfilename in filtered : \n",
					"        absolouteFileName = \"abfss://risk@stfsibnkhackbrku4oli5l4c.dfs.core.windows.net/\" + tickerfilename\n",
					"        print(absolouteFileName)\n",
					"        nqSdf = spark.read.format('csv') \\\n",
					"                    .option('header',True) \\\n",
					"                    .option('multiLine', True) \\\n",
					"                    .load(absolouteFileName)\n",
					"        \n",
					"        consolidatedtweets = consolidatedtweets.append(nqSdf.toPandas())\n",
					"        scoredTweets = pd.DataFrame()\n",
					"        consolidatedtweets['Location'] = consolidatedtweets['Location\\r'].str.strip(r'\\\\r').astype(str)\n",
					"        consolidatedtweets = consolidatedtweets.drop(columns='Location\\r')\n",
					"        \n",
					"      print(\"Before drop\", consolidatedtweets.shape[0])\n",
					"      consolidatedtweets = consolidatedtweets.drop_duplicates(subset=['TweetText'])\n",
					"      print(\"After Drop\", consolidatedtweets.shape[0])\n",
					"\n",
					"      for index, tweet in consolidatedtweets.iterrows():\n",
					"            documents = []\n",
					"            mentions = re.findall(\"@([a-zA-Z0-9]{1,15})\", tweet.TweetText)\n",
					"            topics = re.findall(\"#([a-zA-Z0-9]{1,15})\", tweet.TweetText)\n",
					"            documents.append (\"'\" + tweet.TweetText + \"'\")\n",
					"            tweet['mentions'] = mentions\n",
					"            tweet['topics'] = topics\n",
					"            tweet['Ticker'] = portfolio.Ticker\n",
					"            response = text_analytics_client.analyze_sentiment(documents, language=\"en\")\n",
					"            result = [doc for doc in response if not doc.is_error]\n",
					"            tweet['sentiment'] = result[0].sentiment\n",
					"            tweet['positive'] = result[0].confidence_scores.positive\n",
					"            tweet['negative'] = result[0].confidence_scores.negative\n",
					"            tweet['neutral'] = result[0].confidence_scores.neutral\n",
					"\n",
					"            if tweet.Location : \n",
					"              tweet.Location = tweet.Location.rstrip('\\r')\n",
					"            else :\n",
					"              tweet.Location = \" \"\n",
					"              tweet.Location = tweet.Location.rstrip('\\r')\n",
					"            \n",
					"            scoredTweets = scoredTweets.append(tweet,ignore_index=True) \n",
					"\n",
					"      output = scoredTweets.to_csv(index=False, header=True, encoding = \"utf-8\")\n",
					"      blobService.create_blob_from_text(containerName,  \"TwitterData/scored/\" + str(currDate.year) + \"/\" + str(currDate.month) + \"/\" + str(currDate.day) + \"/\" + portfolio.Ticker + \".csv\", output)\n",
					"    \n",
					"\n",
					"\n",
					"\n",
					"      \n",
					"    \n",
					"        \n",
					"\n",
					"\n",
					"\n",
					"\n",
					"\n",
					"\n",
					"           \n",
					"\n",
					"\n",
					"  \n",
					"\n",
					""
				],
				"attachments": null,
				"execution_count": 16
			}
		]
	}
}